{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b36bd7-645a-4d53-b431-5cd18396412d",
   "metadata": {},
   "source": [
    "This is a Markdown cell\n",
    "\n",
    "no Code will be evaluated\n",
    "\n",
    "[Runbooks.sh](https://github.com/unskript/Awesome-CloudOps-Automation)\n",
    "\n",
    "```python\n",
    "#sample code\n",
    "sum = 4+4\n",
    "print (\"sum\". sume)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62912478-eaf4-4aef-9618-c85694c0573b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'return', 'Ġmaximum', 'Ġvalue', '</s>', 'def', 'Ġmax', '(', 'a', ',', 'b', '):', 'Ġif', 'Ġa', '>', 'b', ':', 'Ġreturn', 'Ġa', 'Ġelse', 'Ġreturn', 'Ġb', '</s>']\n",
      "[0, 30921, 4532, 923, 2, 9232, 19220, 1640, 102, 6, 428, 3256, 114, 10, 15698, 428, 35, 671, 10, 1493, 671, 741, 2]\n",
      "tensor([[[-0.1423,  0.3766,  0.0443,  ..., -0.2513, -0.3099,  0.3183],\n",
      "         [-0.5739,  0.1333,  0.2314,  ..., -0.1240, -0.1219,  0.2033],\n",
      "         [-0.1579,  0.1335,  0.0291,  ...,  0.2340, -0.8801,  0.6216],\n",
      "         ...,\n",
      "         [-0.4042,  0.2284,  0.5241,  ..., -0.2046, -0.2419,  0.7031],\n",
      "         [-0.3894,  0.4603,  0.4797,  ..., -0.3335, -0.6049,  0.4730],\n",
      "         [-0.1433,  0.3785,  0.0450,  ..., -0.2527, -0.3121,  0.3207]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "clean_up_tokenization_spaces = True\n",
    "nl_tokens = tokenizer.tokenize(\"return maximum value\")\n",
    "#print(nl_tokens)\n",
    "code_tokens=tokenizer.tokenize(\"def max(a,b): if a>b: return a else return b\")\n",
    "#print(code_tokens)\n",
    "tokens = [tokenizer.cls_token] + nl_tokens + [tokenizer.sep_token] + code_tokens + [tokenizer.eos_token]\n",
    "print(tokens)\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(tokens_ids)\n",
    "context_embeddings = model(torch.tensor(tokens_ids)[None,:])[0]\n",
    "print(context_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5a009-4636-47ab-a1db-cf5852870d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
